--- a/arch/arm/kernel/entry-armv.S.orig
+++ b/arch/arm/kernel/entry-armv.S
@@ -609,10 +609,10 @@
 	add	pc, pc, r8, lsr #6
 	nop
 
-	w(b)	do_fpe				@ CP#1 (FPE)
-	w(b)	do_fpe				@ CP#2 (FPE)
+	b	do_fpe				@ CP#1 (FPE)
+	b	do_fpe				@ CP#2 (FPE)
 	b	do_vfp				@ CP#10 (VFP)
 	b	do_vfp				@ CP#11 (VFP)
 #ifdef CONFIG_IWMMXT
-	w(b)	do_vfp				@ CP#0 (VFP)
-	w(b)	do_vfp				@ CP#1 (VFP)
+	b	do_vfp				@ CP#0 (VFP)
+	b	do_vfp				@ CP#1 (VFP)
 #else
 	b	do_vfp				@ CP#0 (VFP)
@@ -1279,14 +1279,14 @@
 	@
 	@ initialise processor (return in r0)
 	@
-	w(b)	vector_rst
-	w(b)	vector_und
-	w(ldr)	pc, __vectors_start + 0x1000
-	w(b)	vector_pabt
-	w(b)	vector_dabt
-	w(b)	vector_addrexcptn
-	w(b)	vector_irq
-	w(b)	vector_fiq
+	b	vector_rst
+	b	vector_und
+	ldr	pc, [pc, #0x1000 - 8]
+	b	vector_pabt
+	b	vector_dabt
+	b	vector_addrexcptn
+	b	vector_irq
+	b	vector_fiq
 
 	.globl	__vectors_end
 __vectors_end:
@@ -1150,7 +1150,8 @@
 	@
 	@ r0 = offset to sync
 	@ on entry r0 = address of word to be synchronised
-	swi	__ARM_NR_cacheflush
+	.arm
+	swi	#(__ARM_NR_cacheflush)
 	nop
 	nop
 
@@ -1095,25 +1095,30 @@
 	@
 	@ r8  = ARM architecture version (0x4T, 0x5T, 0x5TE, 0x5TEJ, 0x6)
 	@
+	.arm
 
 	bic	r0, r0, #PSR_ENDSTATE		@ Clear the endianness state
 	orr	r0, r0, #PSR_ISETSTATE		@ Set correct Thumb state for vector
 	sub	lr, lr, #4			@ Adjust LR
 	str	lr, [sp, #S_PC]			@ Save return address
 	mrs	lr, spsr			@ Get SPSR
 	str	lr, [sp, #S_PSR]		@ Save SPSR
 	str	r0, [sp, #S_OLD_R0]		@ Save OLD_R0
 	zero_fp
 
 	@
 	@ Get the equivalent of SVC mode's CPSR in lr
 	@
 	eor	r3, r3, #\mode
 	mov	lr, r3
 	and	lr, lr, #0x0f
 	cmp	lr, #T_ARM			@ Are we in ARM mode?
-	adr	r0, 1f				@ Calculate the jump table address
+	adrl	r0, 1f				@ Calculate the jump table address
 	ldr	lr, [r0, lr, lsl #2]		@ Load from the jump table
 	mov	r0, r9				@ Move the stack pointer value
 	ldr	r9, [sp, #S_PSR]		@ Get the SPSR from stack
 	msr	spsr_cxsf, r9			@ Put the SPSR on the stack
 	and	r9, r9, #0x00000020		@ Extract the T-bit from SPSR
 	teq	r9, #0x00000020			@ Check if we should stay in Thumb
@@ -1132,7 +1137,7 @@
 	@  ARM        Thumb          Jump
 	@  r3 = ARM   r3 = Thumb     Action
 	@  
-	ldr	lr, [pc, lr, lsl #2]		@ Load from the jump table
+	ldr	lr, [pc, lr, lsl #2]		@ Load from the jump table (ARM)
 	mov	lr, lr
 
 	@ We are now ready to branch to the correct handler in ARM state
--- a/arch/arm/mm/proc-v7.S.orig
+++ b/arch/arm/mm/proc-v7.S
@@ -54,7 +54,8 @@
 	mov	pc, lr				@ return to head.S:__ret
 ENDPROC(__v7_setup)
 
-	bic	r1, r1, #1 << 30		@ clear bit 30
+	.arm
+	bic	r1, r1, #(1 << 30)		@ clear bit 30
 	orr	r1, r1, #1 << 25		@ set bit 25
 	mcr	p15, 0, r1, c1, c0, 1		@ write auxiliary control register
 	mov	pc, lr
@@ -324,7 +325,8 @@
 __v7_ca7mp_setup:
 __v7_ca15mp_setup:
 	mov	r10, #(1 << 0)			@ Cache/TLB ops broadcasting
-	orr	r0, r0, #1 << 30		@ L2 unified cache enable
+	.arm
+	orr	r0, r0, #(1 << 30)		@ L2 unified cache enable
 	b	1f
 __v7_ca5mp_setup:
 __v7_ca9mp_setup:
@@ -343,7 +345,8 @@
 	orreq	r0, r0, r10			@ Enable CPU-specific SMP bits
 	mcr	p15, 0, r0, c1, c0, 1		@ write aux ctl reg
 	b	__v7_setup			@ tail call
-# define MULTI_CPU_SECONDARY
+	.arm
+@ define MULTI_CPU_SECONDARY
 
 /*
  *	__v7_proc_info
@@ -355,38 +358,38 @@
 	.macro __v7_proc name, initfunc, mm_mmuflags = 0, io_mmuflags = 0, hwcaps = 0
 	ALT_SMP(.long	PMD_TYPE_SECT | PMD_SECT_AP_WRITE | PMD_SECT_AP_READ | \
 			PMD_SECT_AF | PMD_FLAGS_SMP | \mm_mmuflags)
 	ALT_UP(.long	PMD_TYPE_SECT | PMD_SECT_AP_WRITE | PMD_SECT_AP_READ | \
 			PMD_SECT_AF | PMD_FLAGS_UP | \mm_mmuflags)
 	.long	PMD_TYPE_SECT | PMD_SECT_XN | PMD_SECT_AP_WRITE | \
 		PMD_SECT_AP_READ | PMD_SECT_AF | \io_mmuflags
 	W(b)	\initfunc
+	b	\initfunc
 	.long	cpu_arch_name
 	.long	cpu_elf_name
 	.long	HWCAP_SWP | HWCAP_HALF | HWCAP_THUMB | HWCAP_FAST_MULT | \
 		 HWCAP_EDSP | HWCAP_TLS | \hwcaps
 	.long	cpu_v7_name
 	.long	v7_processor_functions
 	.long	v7wbi_tlb_fns
 	.long	v6_user_fns
 	.long	v7_cache_fns
 	.endm
 
 /*
  * ARM Ltd. Cortex A5 processor.
  */
 	.type   __v7_ca5mp_proc_info, #object
 __v7_ca5mp_proc_info:
 	.long	0x410fc050
 	.long	0xff0ffff0
-	__v7_proc __v7_ca5mp_setup, hwcaps = HWCAP_IDIV
+	__v7_proc __v7_ca5mp_setup, initfunc = __v7_ca5mp_setup, hwcaps = HWCAP_IDIV
 	.size	__v7_ca5mp_proc_info, . - __v7_ca5mp_proc_info
 
 	/*
 	 * ARM Ltd. Cortex A9 processor.
 	 */
 	.type   __v7_ca9mp_proc_info, #object
 __v7_ca9mp_proc_info:
 	.long	0x410fc090
 	.long	0xff0ffff0
-	__v7_proc __v7_ca9mp_setup
+	__v7_proc __v7_ca9mp_setup, initfunc = __v7_ca9mp_setup
 	.size	__v7_ca9mp_proc_info, . - __v7_ca9mp_proc_info
--- a/arch/arm/mm/proc-v7-2level.S.orig
+++ b/arch/arm/mm/proc-v7-2level.S
@@ -366,9 +366,10 @@
 	tst	r3, #L_PTE_PRESENT | L_PTE_YOUNG	@ present and young?
 	movne	r2, #0
 	
-	str	r3, [r0, #2048]!			@ hardware version
+	.arm
+	add	r0, r0, #2048
+	str	r3, [r0]				@ hardware version
 
 	mov	ip, #0
 	mcr	p15, 0, r0, c7, c10, 1		@ clean L1 D line
 	mcr	p15, 0, ip, c7, c10, 4		@ data sync barrier
--- a/arch/arm/include/asm/assembler.h.orig
+++ b/arch/arm/include/asm/assembler.h
@@ -38,6 +38,18 @@
 #define BSYM(sym)	sym + 1
 #endif
 
+/*
+ * Unified function call macros
+ */
+.macro W instr:vararg
+	\instr
+.endm
+
+.macro ARM_BE8 instr, opnd, regs:vararg
+	\instr \opnd, \regs
+.endm
+
+
 /*
  * Add a module name to the __ex_table for C functions.  For asm functions,
  * this should be done directly after the function declaration using the
@@ -192,6 +204,14 @@
 	.endm
 #endif
 
+/*
+ * Instruction set switching macros
+ */
+.macro	set_mode_arm
+	.arm
+.endm
+
+
 /*
  * Data preload for architectures that support it
  */
@@ -309,4 +329,10 @@
 #endif
 #endif
 
+/*
+ * Thumb-2/ARM instruction set helpers
+ */
+#define ALT_SMP(instr...) instr
+#define ALT_UP(instr...) instr
+
 #endif /* __ASM_ASSEMBLER_H__ */