--- a/arch/arm/include/asm/assembler.h
+++ b/arch/arm/include/asm/assembler.h
@@ -19,6 +19,16 @@
 #endif
 #include <asm/ptrace.h>
 
+/*
+ * PostmarketOS: Define architecture version if not already defined
+ */
+#ifndef __LINUX_ARM_ARCH__
+#define __LINUX_ARM_ARCH__ 7
+#endif
+
+/* Force ARM mode build - disable Thumb2 */
+#undef CONFIG_THUMB2_KERNEL
+
 /*
  * Endian independent macros for shifting bytes within registers.
  */
@@ -105,6 +115,10 @@
 #define USER(x...)				\
 9999:	x;					\
 	.pushsection __ex_table,"a";		\
 	.align	3;				\
 	.long	9999b,9001f;			\
 	.popsection
 
 #ifdef CONFIG_SMP
 #define ALT_SMP(instr...)					\
 9998:	instr
 /*
  * Note: if you get assembler errors from ALT_UP() when building with
  * CONFIG_THUMB2_KERNEL, you almost certainly need to use
  * ALT_SMP( W(instr) ... )
  */
 #define ALT_UP(instr...)					\
 	.pushsection ".alt.smp.init", "a"			;\
 	.long	9998b						;\
 9997:	instr							;\
 	.if . - 9997b != 4					;\
 		.error "ALT_UP() content must assemble to exactly 4 bytes";\
 	.endif							;\
 	.popsection
 #define ALT_UP_B(label)					\
 	.equ	up_b_offset, label - 9998b			;\
 	.pushsection ".alt.smp.init", "a"			;\
 	.long	9998b						;\
 	W(b)	. + up_b_offset					;\
 	.popsection
 #else
 #define ALT_SMP(instr...)
 #define ALT_UP(instr...) instr
 #define ALT_UP_B(label) b label
 #endif
 
 /*
  * Instruction barrier
  */
 	.macro	instr_sync
-#if __LINUX_ARM_ARCH__ >= 7
 	isb
-#elif __LINUX_ARM_ARCH__ == 6
-	mcr	p15, 0, r0, c7, c5, 4
-#endif
 	.endm
 
 /*
  * SMP data memory barrier
  */
 	.macro	smp_dmb mode
 #ifdef CONFIG_SMP
-#if __LINUX_ARM_ARCH__ >= 7
 	.ifeqs "\mode","arm"
 	ALT_SMP(dmb	ish)
 	.else
 	ALT_SMP(W(dmb)	ish)
 	.endif
-#elif __LINUX_ARM_ARCH__ == 6
-	ALT_SMP(mcr	p15, 0, r0, c7, c10, 5)	@ dmb
-#else
-#error Incompatible SMP platform
-#endif
 	ALT_UP(nop)
 #endif
 	.endm
 
 #ifdef CONFIG_THUMB2_KERNEL
 	.macro	setmode, mode, reg
 	mov	\reg, #\mode
 	msr	cpsr_c, \reg
 	.endm
 #else
 	.macro	setmode, mode, reg
 	msr	cpsr_c, #\mode
 	.endm
 #endif
 
 /*
  * Helper macro to enter SVC mode cleanly and mask interrupts. reg is
  * a scratch register for the macro to overwrite.
  *
  * This macro is intended for forcing the CPU into SVC mode at boot time.
  * you cannot return to the original mode.
  */
 .macro safe_svcmode_maskall reg:req
-#if __LINUX_ARM_ARCH__ >= 6
 	mrs	\reg , cpsr
 	eor	\reg, \reg, #HYP_MODE
 	tst	\reg, #MODE_MASK
 	bic	\reg , \reg , #MODE_MASK
 	orr	\reg , \reg , #PSR_I_BIT | PSR_F_BIT | SVC_MODE
 THUMB(	orr	\reg , \reg , #PSR_T_BIT	)
 	bne	1f
 	orr	\reg, \reg, #PSR_A_BIT
-	adr	lr, BSYM(2f)
+	adr	lr, 2f
 	msr	spsr_cxsf, \reg
 	__MSR_ELR_HYP(14)
 	__ERET
 1:	msr	cpsr_c, \reg
 2:
-#else
-/*
- * workaround for possibly broken pre-v6 hardware
- * (akita, Sharp Zaurus C-1000, PXA270-based)
- */
-	setmode	PSR_F_BIT | PSR_I_BIT | SVC_MODE, \reg
-#endif
 .endm
 
 /*
